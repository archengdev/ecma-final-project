{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f30c223f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mliv.inference import Vanilla2SLS\n",
    "from mliv.utils import CausalDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "edf067f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   v1     v2  v3  v4  v5  v6  v7         v8        v9  v10  ...  v18  v19  \\\n",
      "0  40  40.50   1  11   0   0  13   8.955383  5.023558    1  ...    3    0   \n",
      "1  41  41.00   1  12   0   0  14   8.993365  5.061540    1  ...    1    0   \n",
      "2  41  41.50   1  12   0   0  14   9.310141  5.378315    1  ...    3    0   \n",
      "3  46  46.25   1  12   0   0  14   9.110465  5.178639    1  ...    4    0   \n",
      "4  46  46.00   1  16   0   0  18  10.310601  6.378776    1  ...    1    0   \n",
      "\n",
      "   v20  v21   v22  v23  v24  v25  v26   v27  \n",
      "0    1    1  10.0    5    0    0    0  1929  \n",
      "1    0    1  10.0    5    0    0    0  1929  \n",
      "2    0    1  10.0    5    0    0    0  1928  \n",
      "3    0    1  10.0    5    0    0    0  1923  \n",
      "4    0    1  10.0    5    0    0    1  1924  \n",
      "\n",
      "[5 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the .dta file\n",
    "df = pd.read_stata(\"angirst.dta\")\n",
    "\n",
    "# Display the first few rows\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6559e92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_stata(\"angrist.dta\")\n",
    "\n",
    "# Split data into train (70%) and temp (30%)\n",
    "train_df, temp_df = train_test_split(df, test_size=0.3, random_state=42)\n",
    "\n",
    "# Split temp into validation (50% of temp, i.e., 15% of total) and test (50% of temp)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "\n",
    "# Save splits to CSV files\n",
    "train_df.to_csv(\"train.csv\", index=False)\n",
    "val_df.to_csv(\"valid.csv\", index=False)\n",
    "test_df.to_csv(\"test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae47b60d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run -1-th experiment for Vanilla2SLS. \n",
      "End. --------------------\n"
     ]
    }
   ],
   "source": [
    "data = CausalDataset('./Data/Demand/0.5_1.0_0.0_10000/1/')\n",
    "\n",
    "model = Vanilla2SLS()\n",
    "model.fit(data)\n",
    "ITE = model.predict(data.train)\n",
    "ATE,_ = model.ATE(data.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "251ebfd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The path: ./Data/Demand/0.5_1.0_0.0_10000/\n",
      "Generate Demand datasets - 0/10. \n",
      "Generate Demand datasets - 1/10. \n",
      "Generate Demand datasets - 2/10. \n",
      "Generate Demand datasets - 3/10. \n",
      "Generate Demand datasets - 4/10. \n",
      "Generate Demand datasets - 5/10. \n",
      "Generate Demand datasets - 6/10. \n",
      "Generate Demand datasets - 7/10. \n",
      "Generate Demand datasets - 8/10. \n",
      "Generate Demand datasets - 9/10. \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'dataName': 'Demand',\n",
       " 'exps': 10,\n",
       " 'num': 10000,\n",
       " 'rho': 0.5,\n",
       " 'alpha': 1.0,\n",
       " 'beta': 0.0,\n",
       " 'seed': 2022,\n",
       " 'num_val': 10000,\n",
       " 'seed_val': 3033,\n",
       " 'seed_tst': 4044}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mliv.dataset.demand import gen_data\n",
    "from mliv.utils import CausalDataset\n",
    "gen_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "950595b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-12.550724338436222\n"
     ]
    }
   ],
   "source": [
    "print(ATE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
