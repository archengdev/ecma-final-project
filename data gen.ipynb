{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10302392",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v3</th>\n",
       "      <th>v5</th>\n",
       "      <th>v6</th>\n",
       "      <th>v7</th>\n",
       "      <th>v10</th>\n",
       "      <th>v11</th>\n",
       "      <th>v12</th>\n",
       "      <th>v13</th>\n",
       "      <th>v14</th>\n",
       "      <th>v15</th>\n",
       "      <th>v17</th>\n",
       "      <th>v18</th>\n",
       "      <th>v19</th>\n",
       "      <th>v20</th>\n",
       "      <th>v21</th>\n",
       "      <th>v23</th>\n",
       "      <th>v24</th>\n",
       "      <th>v25</th>\n",
       "      <th>v26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   v1  v3  v5  v6  v7  v10  v11  v12  v13  v14  v15  v17  v18  v19  v20  v21  \\\n",
       "0  42   2   0   0  11    0    0    1    0    0    0   26    3    0    0    0   \n",
       "1  47   2   1   0  20    1    1    0    0    0    0   41    4    0    0    1   \n",
       "2  33   2   0   0  18    1    0    0    0    0    0   47    3    0    0    0   \n",
       "3  42   2   0   0  14    1    0    0    0    0    0   48    3    0    1    0   \n",
       "4  40   3   0   0  18    0    0    0    0    0    1   36    3    0    0    0   \n",
       "\n",
       "   v23  v24  v25  v26  \n",
       "0   48    0    0    0  \n",
       "1   35    1    0    0  \n",
       "2   52    0    0    0  \n",
       "3    5    1    0    1  \n",
       "4    5    0    0    0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_stata(\"angrist.dta\")\n",
    "# drop columns what we generate later (e.g. education, wage) \n",
    "# and ones that are directly correlated with those columns (year of birth) or irrelevant (census)\n",
    "df = df.drop(columns=['v2', 'v4', 'v8', 'v9', 'v16', 'v22', 'v27'])\n",
    "\n",
    "# helper function to generate synthetic data\n",
    "def generate_synthetic_data(df, n):\n",
    "    synthetic_data = {}\n",
    "    \n",
    "    for col in df.columns:\n",
    "        value_counts = df[col].value_counts(normalize=True) \n",
    "        values = value_counts.index.tolist()\n",
    "        probabilities = value_counts.values\n",
    "\n",
    "        synthetic_data[col] = np.random.choice(values, size=n, p=probabilities)\n",
    "    \n",
    "    return pd.DataFrame(synthetic_data)\n",
    "\n",
    "synthetic_df = generate_synthetic_data(df, 100000)\n",
    "synthetic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c1166dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             v1        v3        v5        v6         v7       v10      v11  \\\n",
      "mean  39.948790  1.883640  0.203950  0.064720  15.022500  0.843000  0.16472   \n",
      "std    5.920983  0.565087  0.402934  0.246032   3.239234  0.363803  0.37093   \n",
      "min   30.000000  0.000000  0.000000  0.000000   0.000000  0.000000  0.00000   \n",
      "max   50.000000  3.000000  1.000000  1.000000  22.000000  1.000000  1.00000   \n",
      "\n",
      "           v12       v13       v14       v15        v17       v18       v19  \\\n",
      "mean  0.048620  0.054780  0.006870  0.126400  30.718710  2.519370  0.081050   \n",
      "std   0.215073  0.227551  0.082601  0.332301  14.776483  1.111727  0.272913   \n",
      "min   0.000000  0.000000  0.000000  0.000000   1.000000  1.000000  0.000000   \n",
      "max   1.000000  1.000000  1.000000  1.000000  99.000000  4.000000  1.000000   \n",
      "\n",
      "           v20       v21        v23       v24       v25      v26  \n",
      "mean  0.212920  0.167060  38.629130  0.077300  0.093970  0.15194  \n",
      "std   0.409374  0.373031  19.939165  0.267068  0.291788  0.36690  \n",
      "min   0.000000  0.000000   0.000000  0.000000  0.000000 -1.00000  \n",
      "max   1.000000  1.000000  52.000000  1.000000  1.000000  1.00000  \n",
      "             v1        v3        v5        v6         v7       v10       v11  \\\n",
      "mean  39.937258  1.881698  0.202178  0.063751  15.018689  0.842850  0.165141   \n",
      "std    5.920283  0.564564  0.401624  0.244309   3.235566  0.363942  0.371308   \n",
      "min   30.000000  0.000000  0.000000  0.000000   0.000000  0.000000  0.000000   \n",
      "max   50.000000  3.000000  1.000000  1.000000  22.000000  1.000000  1.000000   \n",
      "\n",
      "           v12       v13       v14       v15        v17       v18       v19  \\\n",
      "mean  0.048168  0.055629  0.006792  0.127943  30.697552  2.516151  0.081753   \n",
      "std   0.214121  0.229204  0.082132  0.334026  14.757615  1.113988  0.273988   \n",
      "min   0.000000  0.000000  0.000000  0.000000   1.000000  1.000000  0.000000   \n",
      "max   1.000000  1.000000  1.000000  1.000000  99.000000  4.000000  1.000000   \n",
      "\n",
      "           v20       v21        v23       v24       v25       v26  \n",
      "mean  0.212831  0.165188  38.558308  0.076508  0.095494  0.151519  \n",
      "std   0.409309  0.371351  19.990060  0.265809  0.293897  0.366429  \n",
      "min   0.000000  0.000000   0.000000  0.000000  0.000000 -1.000000  \n",
      "max   1.000000  1.000000  52.000000  1.000000  1.000000  1.000000  \n"
     ]
    }
   ],
   "source": [
    "# verify the synthetic data is similar to original\n",
    "summary = synthetic_df.describe().loc[['mean', 'std', 'min', 'max']]\n",
    "print(summary)\n",
    "summary = df.describe().loc[['mean', 'std', 'min', 'max']]\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61959a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69e3671a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic test set\n",
    "N = 100000\n",
    "filepath = './basic/'\n",
    "\n",
    "u1 = np.random.normal(0, 1, N) # educ shock\n",
    "v1 = np.random.normal(0, 1, N)  # wage shock\n",
    "qob = np.random.randint(1, 5, size=N) \n",
    "age = np.random.randint(30, 51, size=N)\n",
    "\n",
    "# straightforward, test set: ./basic/\n",
    "educ = 10 + 1.5 * qob + u1\n",
    "wage = 5 + 2.5 * educ + v1\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'y1': wage,        # Outcome: Wages\n",
    "    'x1': age,        # Other variable: Schooling\n",
    "    'z1': qob,        # Instrument\n",
    "    't1' : educ         # Treatment\n",
    "})\n",
    "\n",
    "angrist = pd.read_stata(\"angrist.dta\")\n",
    "synth = generate_synthetic_data(angrist, N)\n",
    "synth.columns = ['x' + str(i) for i in range(2, len(angrist.columns) + 2)]\n",
    "combined_df = pd.concat([df, synthetic_df], axis=1)\n",
    "if not os.path.isdir(filepath):\n",
    "    os.makedirs(filepath)\n",
    "train_df, temp_df = train_test_split(combined_df, test_size=0.3)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5)\n",
    "train_df.to_csv(filepath + \"train.csv\", index=False)\n",
    "val_df.to_csv(filepath + \"valid.csv\", index=False)\n",
    "test_df.to_csv(filepath + \"test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f72e5ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one weak instrument\n",
    "N = 100000\n",
    "filepath = './weak/'\n",
    "\n",
    "u1 = np.random.normal(0, 1, N) # educ shock\n",
    "v1 = np.random.normal(0, 1, N)  # wage shock\n",
    "qob = np.random.randint(1, 5, size=N) \n",
    "age = np.random.randint(30, 51, size=N)\n",
    "\n",
    "educ = 10 + 0.1 * qob + u1\n",
    "wage = 5 + 2.5 * educ + v1\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'y1': wage,        # Outcome: Wages\n",
    "    'x1': age,        # Other variable: Schooling\n",
    "    'z1': qob,        # Instrument\n",
    "    't1' : educ         # Treatment\n",
    "})\n",
    "\n",
    "angrist = pd.read_stata(\"angrist.dta\")\n",
    "synth = generate_synthetic_data(angrist, N)\n",
    "synth.columns = ['x' + str(i) for i in range(2, len(angrist.columns) + 2)]\n",
    "combined_df = pd.concat([df, synthetic_df], axis=1)\n",
    "if not os.path.isdir(filepath):\n",
    "    os.makedirs(filepath)\n",
    "train_df, temp_df = train_test_split(combined_df, test_size=0.3)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5)\n",
    "train_df.to_csv(filepath + \"train.csv\", index=False)\n",
    "val_df.to_csv(filepath + \"valid.csv\", index=False)\n",
    "test_df.to_csv(filepath + \"test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6480000e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# strong but endogenous instrument\n",
    "N = 100000\n",
    "filepath = './endog/'\n",
    "\n",
    "u1 = np.random.normal(0, 1, N) # educ shock\n",
    "v1 = np.random.normal(0, 1, N)  # wage shock\n",
    "g1 = np.random.normal(0, 1, N)  # 'health' shock\n",
    "qob = np.random.randint(1, 5, size=N) \n",
    "age = np.random.randint(30, 51, size=N)\n",
    "\n",
    "educ = 10 + 1.5 * qob + u1\n",
    "health = 3 + 0.5 * qob + g1 # arbitrary unobserved variable for endogenous effect\n",
    "wage = 5 + 2.5 * educ + health + v1\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'y1': wage,        # Outcome: Wages\n",
    "    'x1': age,        # Other variable: Schooling\n",
    "    'z1': qob,        # Instrument\n",
    "    't1' : educ         # Treatment\n",
    "})\n",
    "\n",
    "angrist = pd.read_stata(\"angrist.dta\")\n",
    "synth = generate_synthetic_data(angrist, N)\n",
    "synth.columns = ['x' + str(i) for i in range(2, len(angrist.columns) + 2)]\n",
    "combined_df = pd.concat([df, synthetic_df], axis=1)\n",
    "if not os.path.isdir(filepath):\n",
    "    os.makedirs(filepath)\n",
    "train_df, temp_df = train_test_split(combined_df, test_size=0.3)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5)\n",
    "train_df.to_csv(filepath + \"train.csv\", index=False)\n",
    "val_df.to_csv(filepath + \"valid.csv\", index=False)\n",
    "test_df.to_csv(filepath + \"test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c94994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# many weak\n",
    "N = 100000\n",
    "filepath = './manyweak/'\n",
    "\n",
    "angrist = pd.read_stata(\"angrist.dta\")\n",
    "synth = generate_synthetic_data(angrist, N)\n",
    "synth.columns = ['x' + str(i) for i in range(2, len(angrist.columns) + 2)]\n",
    "\n",
    "u1 = np.random.normal(0, 1, N) # educ shock\n",
    "v1 = np.random.normal(0, 1, N)  # wage shock\n",
    "qob = np.random.randint(1, 5, size=N) \n",
    "age = np.random.randint(30, 51, size=N)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'u1': u1,    \n",
    "    'v1': v1,   \n",
    "    'x1': age,       \n",
    "    'z1' : qob         \n",
    "})\n",
    "\n",
    "combined_df = pd.concat([df, synthetic_df], axis=1)\n",
    "combined_df['const'] = 1\n",
    "\n",
    "combined_df.head()\n",
    "\n",
    "\n",
    "weights = {'v1': 0, 'const': 10, 'u1': 1}  \n",
    "for col in combined_df.columns:\n",
    "    if col not in weights:\n",
    "        weights[col] = 0.1 + np.random.normal(0, 1)\n",
    "\n",
    "selected_columns = list(weights.keys())\n",
    "\n",
    "t1 = np.array([\n",
    "    sum(row[col] * weights[col] for col in selected_columns)\n",
    "    for _, row in combined_df.iterrows()\n",
    "])\n",
    "\n",
    "t1 = t1[:,0]\n",
    "combined_df['t1'] = t1\n",
    "\n",
    "# wage = 5 + 2.5 educ + v1\n",
    "weights = { 'const': 5, 'v1': 1, 't1': 2.5}  \n",
    "selected_columns = ['const', 'v1', 't1']\n",
    "y1 = np.array([\n",
    "    sum(row[col] * weights[col] for col in selected_columns)\n",
    "    for _, row in combined_df.iterrows()\n",
    "])\n",
    "\n",
    "y1 = y1[:,0]\n",
    "combined_df['y1'] = y1\n",
    "\n",
    "if not os.path.isdir(filepath):\n",
    "    os.makedirs(filepath)\n",
    "train_df, temp_df = train_test_split(combined_df, test_size=0.3)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5)\n",
    "train_df.to_csv(filepath + \"train.csv\", index=False)\n",
    "val_df.to_csv(filepath + \"valid.csv\", index=False)\n",
    "test_df.to_csv(filepath + \"test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfe8197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# many weak, one strong\n",
    "N = 100000\n",
    "filepath = './manyweak1strong/'\n",
    "\n",
    "angrist = pd.read_stata(\"angrist.dta\")\n",
    "synth = generate_synthetic_data(angrist, N)\n",
    "synth.columns = ['x' + str(i) for i in range(2, len(angrist.columns) + 2)]\n",
    "\n",
    "u1 = np.random.normal(0, 1, N) # educ shock\n",
    "v1 = np.random.normal(0, 1, N)  # wage shock\n",
    "qob = np.random.randint(1, 5, size=N) \n",
    "age = np.random.randint(30, 51, size=N)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'u1': u1,    \n",
    "    'v1': v1,   \n",
    "    'x1': age,       \n",
    "    'z1' : qob         \n",
    "})\n",
    "\n",
    "combined_df = pd.concat([df, synthetic_df], axis=1)\n",
    "combined_df['const'] = 1\n",
    "\n",
    "combined_df.head()\n",
    "\n",
    "\n",
    "weights = {'z1': 1.5, 'v1': 0, 'const': 10, 'u1': 1}  \n",
    "for col in combined_df.columns:\n",
    "    if col not in weights:\n",
    "        weights[col] = 0.1 + np.random.normal(0, 1)\n",
    "\n",
    "selected_columns = list(weights.keys())\n",
    "\n",
    "t1 = np.array([\n",
    "    sum(row[col] * weights[col] for col in selected_columns)\n",
    "    for _, row in combined_df.iterrows()\n",
    "])\n",
    "\n",
    "t1 = t1[:,0]\n",
    "combined_df['t1'] = t1\n",
    "\n",
    "# wage = 5 + 2.5 educ + v1\n",
    "weights = { 'const': 5, 'v1': 1, 't1': 2.5}  \n",
    "selected_columns = ['const', 'v1', 't1']\n",
    "y1 = np.array([\n",
    "    sum(row[col] * weights[col] for col in selected_columns)\n",
    "    for _, row in combined_df.iterrows()\n",
    "])\n",
    "\n",
    "y1 = y1[:,0]\n",
    "combined_df['y1'] = y1\n",
    "\n",
    "if not os.path.isdir(filepath):\n",
    "    os.makedirs(filepath)\n",
    "train_df, temp_df = train_test_split(combined_df, test_size=0.3)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5)\n",
    "train_df.to_csv(filepath + \"train.csv\", index=False)\n",
    "val_df.to_csv(filepath + \"valid.csv\", index=False)\n",
    "test_df.to_csv(filepath + \"test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e50f9c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mliv.inference import Vanilla2SLS\n",
    "from mliv.utils import CausalDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c221767d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run -1-th experiment for Vanilla2SLS. \n",
      "End. --------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.462296907614629"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = CausalDataset('./manyweak/')\n",
    "\n",
    "model = Vanilla2SLS()\n",
    "model.fit(data)\n",
    "ITE = model.predict(data.train)\n",
    "ATE,_ = model.ATE(data.train)\n",
    "\n",
    "ATE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
