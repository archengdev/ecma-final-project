{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10302392",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v3</th>\n",
       "      <th>v5</th>\n",
       "      <th>v6</th>\n",
       "      <th>v7</th>\n",
       "      <th>v10</th>\n",
       "      <th>v11</th>\n",
       "      <th>v12</th>\n",
       "      <th>v13</th>\n",
       "      <th>v14</th>\n",
       "      <th>v15</th>\n",
       "      <th>v17</th>\n",
       "      <th>v18</th>\n",
       "      <th>v19</th>\n",
       "      <th>v20</th>\n",
       "      <th>v21</th>\n",
       "      <th>v23</th>\n",
       "      <th>v24</th>\n",
       "      <th>v25</th>\n",
       "      <th>v26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   v1  v3  v5  v6  v7  v10  v11  v12  v13  v14  v15  v17  v18  v19  v20  v21  \\\n",
       "0  42   2   0   0  15    1    0    0    0    0    0   36    2    0    1    0   \n",
       "1  40   3   0   0  16    1    0    0    0    0    1   18    2    0    1    0   \n",
       "2  43   2   0   0  22    1    0    0    0    0    0   17    4    0    0    0   \n",
       "3  45   2   0   0  16    0    0    0    0    0    1   40    3    0    1    0   \n",
       "4  46   3   0   0  14    1    1    0    0    0    0   17    1    1    1    0   \n",
       "\n",
       "   v23  v24  v25  v26  \n",
       "0   52    0    0    0  \n",
       "1   52    0    0    1  \n",
       "2   52    0    0    0  \n",
       "3   36    0    0    0  \n",
       "4   52    0    1    0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_stata(\"angrist.dta\")\n",
    "# drop columns what we generate later (e.g. education, wage) \n",
    "# and ones that are directly correlated with those columns (year of birth) or irrelevant (census)\n",
    "df = df.drop(columns=['v2', 'v4', 'v8', 'v9', 'v16', 'v22', 'v27'])\n",
    "\n",
    "# helper function to generate synthetic data\n",
    "def generate_synthetic_data(df, n):\n",
    "    synthetic_data = {}\n",
    "    \n",
    "    for col in df.columns:\n",
    "        value_counts = df[col].value_counts(normalize=True) \n",
    "        values = value_counts.index.tolist()\n",
    "        probabilities = value_counts.values\n",
    "\n",
    "        synthetic_data[col] = np.random.choice(values, size=n, p=probabilities)\n",
    "    \n",
    "    return pd.DataFrame(synthetic_data)\n",
    "\n",
    "synthetic_df = generate_synthetic_data(df, 100000)\n",
    "synthetic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2c1166dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            v3        v5        v6         v7       v10       v11       v12  \\\n",
      "mean  1.880000  0.201770  0.063320  15.022690  0.843960  0.165250  0.048410   \n",
      "std   0.565122  0.401323  0.243539   3.236044  0.362895  0.371408  0.214632   \n",
      "min   0.000000  0.000000  0.000000   0.000000  0.000000  0.000000  0.000000   \n",
      "max   3.000000  1.000000  1.000000  22.000000  1.000000  1.000000  1.000000   \n",
      "\n",
      "           v13      v14       v15        v17       v19      v20       v21  \\\n",
      "mean  0.055870  0.00658  0.128780  30.775940  0.082340  0.21340  0.165300   \n",
      "std   0.229672  0.08085  0.334958  14.664968  0.274883  0.40971  0.371453   \n",
      "min   0.000000  0.00000  0.000000   1.000000  0.000000  0.00000  0.000000   \n",
      "max   1.000000  1.00000  1.000000  99.000000  1.000000  1.00000  1.000000   \n",
      "\n",
      "           v23       v24       v25       v26  \n",
      "mean  38.63186  0.075390  0.094170  0.149830  \n",
      "std   19.93551  0.264021  0.292067  0.365161  \n",
      "min    0.00000  0.000000  0.000000 -1.000000  \n",
      "max   52.00000  1.000000  1.000000  1.000000  \n",
      "            v3        v5        v6         v7       v10       v11       v12  \\\n",
      "mean  1.881698  0.202178  0.063751  15.018689  0.842850  0.165141  0.048168   \n",
      "std   0.564564  0.401624  0.244309   3.235566  0.363942  0.371308  0.214121   \n",
      "min   0.000000  0.000000  0.000000   0.000000  0.000000  0.000000  0.000000   \n",
      "max   3.000000  1.000000  1.000000  22.000000  1.000000  1.000000  1.000000   \n",
      "\n",
      "           v13       v14       v15        v17       v19       v20       v21  \\\n",
      "mean  0.055629  0.006792  0.127943  30.697552  0.081753  0.212831  0.165188   \n",
      "std   0.229204  0.082132  0.334026  14.757615  0.273988  0.409309  0.371351   \n",
      "min   0.000000  0.000000  0.000000   1.000000  0.000000  0.000000  0.000000   \n",
      "max   1.000000  1.000000  1.000000  99.000000  1.000000  1.000000  1.000000   \n",
      "\n",
      "            v23       v24       v25       v26  \n",
      "mean  38.558308  0.076508  0.095494  0.151519  \n",
      "std   19.990060  0.265809  0.293897  0.366429  \n",
      "min    0.000000  0.000000  0.000000 -1.000000  \n",
      "max   52.000000  1.000000  1.000000  1.000000  \n"
     ]
    }
   ],
   "source": [
    "# verify the synthetic data is similar to original\n",
    "summary = synthetic_df.describe().loc[['mean', 'std', 'min', 'max']]\n",
    "print(summary)\n",
    "summary = df.describe().loc[['mean', 'std', 'min', 'max']]\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61959a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e3671a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic test set\n",
    "N = 100000\n",
    "filepath = './basic/'\n",
    "\n",
    "u1 = np.random.normal(0, 1, N) # educ shock\n",
    "v1 = np.random.normal(0, 1, N)  # wage shock\n",
    "qob = np.random.randint(1, 5, size=N) \n",
    "age = np.random.randint(30, 51, size=N)\n",
    "\n",
    "# straightforward, test set: ./basic/\n",
    "educ = 10 + 1.5 * qob + u1\n",
    "wage = 5 + 2.5 * educ + v1\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'y1': wage,        # Outcome: Wages\n",
    "    'x1': age,        # Other variable: Schooling\n",
    "    'z1': qob,        # Instrument\n",
    "    't1' : educ         # Treatment\n",
    "})\n",
    "\n",
    "angrist = pd.read_stata(\"angrist.dta\")\n",
    "synth = generate_synthetic_data(angrist, N)\n",
    "synth.columns = ['x' + str(i) for i in range(2, len(angrist.columns) + 2)]\n",
    "combined_df = pd.concat([df, synthetic_df], axis=1)\n",
    "if not os.path.isdir(filepath):\n",
    "    os.makedirs(filepath)\n",
    "train_df, temp_df = train_test_split(combined_df, test_size=0.3)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5)\n",
    "train_df.to_csv(filepath + \"train.csv\", index=False)\n",
    "val_df.to_csv(filepath + \"valid.csv\", index=False)\n",
    "test_df.to_csv(filepath + \"test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f72e5ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one weak instrument\n",
    "N = 100000\n",
    "filepath = './weak/'\n",
    "\n",
    "u1 = np.random.normal(0, 1, N) # educ shock\n",
    "v1 = np.random.normal(0, 1, N)  # wage shock\n",
    "qob = np.random.randint(1, 5, size=N) \n",
    "age = np.random.randint(30, 51, size=N)\n",
    "\n",
    "educ = 10 + 0.01 * qob + u1\n",
    "wage = 5 + 2.5 * educ + v1\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'y1': wage,        # Outcome: Wages\n",
    "    'x1': age,        # Other variable: Schooling\n",
    "    'z1': qob,        # Instrument\n",
    "    't1' : educ         # Treatment\n",
    "})\n",
    "\n",
    "angrist = pd.read_stata(\"angrist.dta\")\n",
    "synth = generate_synthetic_data(angrist, N)\n",
    "synth.columns = ['x' + str(i) for i in range(2, len(angrist.columns) + 2)]\n",
    "combined_df = pd.concat([df, synthetic_df], axis=1)\n",
    "if not os.path.isdir(filepath):\n",
    "    os.makedirs(filepath)\n",
    "train_df, temp_df = train_test_split(combined_df, test_size=0.3)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5)\n",
    "train_df.to_csv(filepath + \"train.csv\", index=False)\n",
    "val_df.to_csv(filepath + \"valid.csv\", index=False)\n",
    "test_df.to_csv(filepath + \"test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6480000e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# strong but endogenous instrument\n",
    "N = 100000\n",
    "filepath = './endog/'\n",
    "\n",
    "u1 = np.random.normal(0, 1, N) # educ shock\n",
    "v1 = np.random.normal(0, 1, N)  # wage shock\n",
    "qob = np.random.randint(1, 5, size=N) \n",
    "age = np.random.randint(30, 51, size=N)\n",
    "\n",
    "educ = 10 + 1.5 * qob + u1\n",
    "wage = 5 + 2.5 * educ + 0.5 * qob + v1\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'y1': wage,        # Outcome: Wages\n",
    "    'x1': age,        # Other variable: Schooling\n",
    "    'z1': qob,        # Instrument\n",
    "    't1' : educ         # Treatment\n",
    "})\n",
    "\n",
    "angrist = pd.read_stata(\"angrist.dta\")\n",
    "synth = generate_synthetic_data(angrist, N)\n",
    "synth.columns = ['x' + str(i) for i in range(2, len(angrist.columns) + 2)]\n",
    "combined_df = pd.concat([df, synthetic_df], axis=1)\n",
    "if not os.path.isdir(filepath):\n",
    "    os.makedirs(filepath)\n",
    "train_df, temp_df = train_test_split(combined_df, test_size=0.3)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5)\n",
    "train_df.to_csv(filepath + \"train.csv\", index=False)\n",
    "val_df.to_csv(filepath + \"valid.csv\", index=False)\n",
    "test_df.to_csv(filepath + \"test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "595fdea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one weak and endog\n",
    "N = 100000\n",
    "filepath = './weakendog/'\n",
    "\n",
    "u1 = np.random.normal(0, 1, N) # educ shock\n",
    "v1 = np.random.normal(0, 1, N)  # wage shock\n",
    "qob = np.random.randint(1, 5, size=N) \n",
    "age = np.random.randint(30, 51, size=N)\n",
    "\n",
    "educ = 10 + 0.01 * qob + u1\n",
    "wage = 5 + 2.5 * educ + 0.5 * qob + v1\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'y1': wage,        # Outcome: Wages\n",
    "    'x1': age,        # Other variable: Schooling\n",
    "    'z1': qob,        # Instrument\n",
    "    't1' : educ         # Treatment\n",
    "})\n",
    "\n",
    "angrist = pd.read_stata(\"angrist.dta\")\n",
    "synth = generate_synthetic_data(angrist, N)\n",
    "synth.columns = ['x' + str(i) for i in range(2, len(angrist.columns) + 2)]\n",
    "combined_df = pd.concat([df, synthetic_df], axis=1)\n",
    "if not os.path.isdir(filepath):\n",
    "    os.makedirs(filepath)\n",
    "train_df, temp_df = train_test_split(combined_df, test_size=0.3)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5)\n",
    "train_df.to_csv(filepath + \"train.csv\", index=False)\n",
    "val_df.to_csv(filepath + \"valid.csv\", index=False)\n",
    "test_df.to_csv(filepath + \"test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "67c94994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# many weak\n",
    "N = 100000\n",
    "filepath = './manyweak/'\n",
    "\n",
    "angrist = pd.read_stata(\"angrist.dta\")\n",
    "synth = generate_synthetic_data(angrist, N)\n",
    "synth.columns = ['x' + str(i) for i in range(2, len(angrist.columns) + 2)]\n",
    "\n",
    "u1 = np.random.normal(0, 1, N) # educ shock\n",
    "v1 = np.random.normal(0, 1, N)  # wage shock\n",
    "qob = np.random.randint(1, 5, size=N) \n",
    "age = np.random.randint(30, 51, size=N)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'u1': u1,    \n",
    "    'v1': v1,   \n",
    "    'x1': age,       \n",
    "    'z1' : qob         \n",
    "})\n",
    "\n",
    "combined_df = pd.concat([df, synthetic_df], axis=1)\n",
    "combined_df['const'] = 1\n",
    "\n",
    "combined_df.head()\n",
    "\n",
    "\n",
    "weights = {'v1': 0, 'const': 10, 'u1': 1}  \n",
    "for col in combined_df.columns:\n",
    "    if col not in weights:\n",
    "        weights[col] = 0.01\n",
    "\n",
    "selected_columns = list(weights.keys())\n",
    "\n",
    "t1 = np.array([\n",
    "    sum(row[col] * weights[col] for col in selected_columns)\n",
    "    for _, row in combined_df.iterrows()\n",
    "])\n",
    "\n",
    "t1 = t1[:,0]\n",
    "combined_df['t1'] = t1\n",
    "\n",
    "# wage = 5 + 1.5 educ + v1\n",
    "weights = { 'const': 5, 'v1': 1, 't1': 1.5}  \n",
    "selected_columns = ['const', 'v1', 't1']\n",
    "y1 = np.array([\n",
    "    sum(row[col] * weights[col] for col in selected_columns)\n",
    "    for _, row in combined_df.iterrows()\n",
    "])\n",
    "\n",
    "y1 = y1[:,0]\n",
    "combined_df['y1'] = y1\n",
    "\n",
    "if not os.path.isdir(filepath):\n",
    "    os.makedirs(filepath)\n",
    "train_df, temp_df = train_test_split(combined_df, test_size=0.3)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5)\n",
    "train_df.to_csv(filepath + \"train.csv\", index=False)\n",
    "val_df.to_csv(filepath + \"valid.csv\", index=False)\n",
    "test_df.to_csv(filepath + \"test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfe8197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# many weak, one strong\n",
    "N = 100000\n",
    "filepath = './manyweak1strong/'\n",
    "\n",
    "angrist = pd.read_stata(\"angrist.dta\")\n",
    "synth = generate_synthetic_data(angrist, N)\n",
    "synth.columns = ['x' + str(i) for i in range(2, len(angrist.columns) + 2)]\n",
    "\n",
    "u1 = np.random.normal(0, 1, N) # educ shock\n",
    "v1 = np.random.normal(0, 1, N)  # wage shock\n",
    "qob = np.random.randint(1, 5, size=N) \n",
    "age = np.random.randint(30, 51, size=N)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'u1': u1,    \n",
    "    'v1': v1,   \n",
    "    'x1': age,       \n",
    "    'z1' : qob         \n",
    "})\n",
    "\n",
    "combined_df = pd.concat([df, synthetic_df], axis=1)\n",
    "combined_df['const'] = 1\n",
    "\n",
    "combined_df.head()\n",
    "\n",
    "\n",
    "weights = {'z1': 1.5, 'v1': 0, 'const': 10, 'u1': 1}  \n",
    "for col in combined_df.columns:\n",
    "    if col not in weights:\n",
    "        weights[col] = 0.01\n",
    "\n",
    "selected_columns = list(weights.keys())\n",
    "\n",
    "t1 = np.array([\n",
    "    sum(row[col] * weights[col] for col in selected_columns)\n",
    "    for _, row in combined_df.iterrows()\n",
    "])\n",
    "\n",
    "t1 = t1[:,0]\n",
    "combined_df['t1'] = t1\n",
    "\n",
    "# wage = 5 + 1.5 educ + v1\n",
    "weights = { 'const': 5, 'v1': 1, 't1': 1.5}  \n",
    "selected_columns = ['const', 'v1', 't1']\n",
    "y1 = np.array([\n",
    "    sum(row[col] * weights[col] for col in selected_columns)\n",
    "    for _, row in combined_df.iterrows()\n",
    "])\n",
    "\n",
    "y1 = y1[:,0]\n",
    "combined_df['y1'] = y1\n",
    "\n",
    "if not os.path.isdir(filepath):\n",
    "    os.makedirs(filepath)\n",
    "train_df, temp_df = train_test_split(combined_df, test_size=0.3)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5)\n",
    "train_df.to_csv(filepath + \"train.csv\", index=False)\n",
    "val_df.to_csv(filepath + \"valid.csv\", index=False)\n",
    "test_df.to_csv(filepath + \"test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c221767d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run -1-th experiment for Vanilla2SLS. \n",
      "End. --------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.832858044676648"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = CausalDataset('./endog')\n",
    "\n",
    "model = Vanilla2SLS()\n",
    "model.fit(data)\n",
    "ITE = model.predict(data.train)\n",
    "ATE,_ = model.ATE(data.train)\n",
    "\n",
    "ATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087ebb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### vanilla 2sls works, simple model?\n",
    "u1 = np.random.normal(0, 1, N) # educ shock\n",
    "v1 = np.random.normal(0, 1, N)  # wage shock\n",
    "qob = np.random.randint(1, 5, size=N) \n",
    "age = np.random.randint(30, 41, size=N)\n",
    "\n",
    "educ = 10 + 5 * qob + u1\n",
    "wage = 5 + 3.5 * educ + v1\n",
    "\n",
    "# weak instrument test, vanilla 2sls doesn't work\n",
    "educ = 10 + 0.01 * qob + u1\n",
    "wage = 5 + 3.5 * educ + v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "20371cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run -1-th experiment for Vanilla2SLS. \n",
      "End. --------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.1659505273539454"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set seed for reproducibility\n",
    "# np.random.seed(42)\n",
    "\n",
    "# Simulate data\n",
    "N = 100000  # Number of observations\n",
    "\n",
    "# maybe this works? vanilla does not see the effect of compulsory schooling on wages\n",
    "u1 = np.random.normal(0, 1, N) # educ shock\n",
    "v1 = np.random.normal(0, 1, N)  # wage shock\n",
    "qob = np.random.randint(1, 5, size=N) \n",
    "age = np.random.randint(30, 41, size=N)\n",
    "\n",
    "\n",
    "educ = 10 + 0.01 * qob + u1\n",
    "wage = 5 + 3.5 * educ + v1\n",
    "\n",
    "# Create DataFrame with labeled columns\n",
    "df = pd.DataFrame({\n",
    "    'y1': wage,        # Outcome: Wages\n",
    "    'x1': age,        # Other variable: Schooling\n",
    "    'z1': qob,        # Instrument\n",
    "    't1': educ         # Treatment\n",
    "})\n",
    "\n",
    "# Save DataFrame to CSV\n",
    "df.to_csv('generated_data.csv', index=False)\n",
    "\n",
    "df = pd.read_csv(\"generated_data.csv\")\n",
    "train_df, temp_df = train_test_split(df, test_size=0.3, random_state=42)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "train_df.to_csv(\"train.csv\", index=False)\n",
    "val_df.to_csv(\"valid.csv\", index=False)\n",
    "test_df.to_csv(\"test.csv\", index=False)\n",
    "\n",
    "data = CausalDataset('./')\n",
    "\n",
    "model = Vanilla2SLS()\n",
    "model.fit(data)\n",
    "ITE = model.predict(data.train)\n",
    "ATE,_ = model.ATE(data.train)\n",
    "\n",
    "ATE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f7d40f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mliv.inference import Vanilla2SLS\n",
    "from mliv.utils import CausalDataset\n",
    "from mliv.inference import Poly2SLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112c20c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def genData(filepath, N=100000):\n",
    "    u1 = np.random.normal(0, 1, N) # educ shock\n",
    "    v1 = np.random.normal(0, 1, N)  # wage shock\n",
    "    qob = np.random.randint(1, 5, size=N) \n",
    "    age = np.random.randint(30, 51, size=N)\n",
    "    \n",
    "    # straightforward, test set: ./basic/\n",
    "    # educ = 10 + 1.5 * qob + u1\n",
    "    # wage = 5 + 2.5 * educ + v1\n",
    "\n",
    "    # weak instrument, ./weak/\n",
    "    educ = 10 + 0.01 * qob + u1\n",
    "    wage = 5 + 2.5 * educ + v1\n",
    "    \n",
    "    # Create DataFrame with labeled columns\n",
    "    df = pd.DataFrame({\n",
    "        'y1': wage,        # Outcome: Wages\n",
    "        'x1': age,        # Other variable: Schooling\n",
    "        'z1': qob,        # Instrument\n",
    "        't1' : educ         # Treatment\n",
    "    })\n",
    "    \n",
    "    angrist = pd.read_stata(\"angrist.dta\")\n",
    "    synth = generate_synthetic_data(angrist, N)\n",
    "    synth.columns = ['x' + str(i) for i in range(2, len(angrist.columns) + 2)]\n",
    "    combined_df = pd.concat([df, synthetic_df], axis=1)\n",
    "    if not os.path.isdir(filepath):\n",
    "        os.makedirs(filepath)\n",
    "    train_df, temp_df = train_test_split(combined_df, test_size=0.3)\n",
    "    val_df, test_df = train_test_split(temp_df, test_size=0.5)\n",
    "    train_df.to_csv(filepath + \"train.csv\", index=False)\n",
    "    val_df.to_csv(filepath + \"valid.csv\", index=False)\n",
    "    test_df.to_csv(filepath + \"test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "504fe757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run -1-th experiment for Vanilla2SLS. \n",
      "End. --------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.1659505273539454"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df = pd.read_csv(\"generated_data.csv\")\n",
    "train_df, temp_df = train_test_split(df, test_size=0.3, random_state=42)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "train_df.to_csv(\"train.csv\", index=False)\n",
    "val_df.to_csv(\"valid.csv\", index=False)\n",
    "test_df.to_csv(\"test.csv\", index=False)\n",
    "\n",
    "data = CausalDataset('./')\n",
    "\n",
    "model = Vanilla2SLS()\n",
    "model.fit(data)\n",
    "ITE = model.predict(data.train)\n",
    "ATE,_ = model.ATE(data.train)\n",
    "\n",
    "ATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fd8119",
   "metadata": {},
   "outputs": [],
   "source": [
    "### vanilla 2sls works, simple model?\n",
    "u1 = np.random.normal(0, 1, N) # educ shock\n",
    "v1 = np.random.normal(0, 1, N)  # wage shock\n",
    "qob = np.random.randint(1, 5, size=N) \n",
    "age = np.random.randint(30, 41, size=N)\n",
    "\n",
    "educ = 10 + 5 * qob + u1\n",
    "wage = 5 + 3.5 * educ + v1\n",
    "\n",
    "# weak instrument test, vanilla 2sls doesn't work\n",
    "educ = 10 + 0.01 * qob + u1\n",
    "wage = 5 + 3.5 * educ + v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6be65835",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = np.random.normal(0, 1, N)  # wage shock\n",
    "nu = np.random.normal(0, 1, N) # educ shock\n",
    "\n",
    "# x1 = np.random.normal(0, 1, N) # age\n",
    "\n",
    "t1 = np.random.binomial(10, 0.5, N)  # compulsory\n",
    "z1 = np.random.normal(0, 1, N) # qob\n",
    "e = np.random.normal(0, 1, N) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e9237d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to 'generated_data.csv'\n",
      "Estimated effect of schooling (2SLS): -0.0000\n",
      "Estimated effect of treatment (2SLS): 1.5000\n"
     ]
    }
   ],
   "source": [
    "# gives nothing\n",
    "x1 = e + 1.5 * t1 + 0.5 * z1  #educ\n",
    "y1 = 10 + 3 * x1\n",
    "\n",
    "# gives 1.5\n",
    "x1 = 3 + 1.5 * t1 + 0.5 * z1  #educ\n",
    "y1 = 10 + 3 + 1.5 * t1\n",
    "\n",
    "\n",
    "# Create DataFrame with labeled columns\n",
    "df = pd.DataFrame({\n",
    "    'y1': y1,        # Outcome: Wages\n",
    "    'x1': x1,        # Other variable: Schooling\n",
    "    'z1': z1,        # Instrument\n",
    "    't1': t1         # Treatment\n",
    "})\n",
    "\n",
    "# Save DataFrame to CSV\n",
    "df.to_csv('generated_data.csv', index=False)\n",
    "print(\"Data saved to 'generated_data.csv'\")\n",
    "\n",
    "# ------------------------- 2SLS Implementation -------------------------\n",
    "# Stage 1: Regress treatment (t1) on instrument (z1)\n",
    "X_first_stage = np.column_stack((z1, t1))  # IV and Treatment as predictors\n",
    "first_stage_model = LinearRegression()\n",
    "first_stage_model.fit(X_first_stage, x1)\n",
    "x1_hat = first_stage_model.predict(X_first_stage)  # Predicted schooling\n",
    "\n",
    "# Stage 2: Regress outcome (y1) on predicted schooling (x1_hat) and treatment (t1)\n",
    "X_second_stage = np.column_stack((x1_hat, t1))  # Predicted schooling + Treatment\n",
    "second_stage_model = LinearRegression()\n",
    "second_stage_model.fit(X_second_stage, y1)\n",
    "beta_s_2sls = second_stage_model.coef_[0]  # Effect of schooling on wages (from 2SLS)\n",
    "beta_t_2sls = second_stage_model.coef_[1]  # Effect of treatment on wages (from 2SLS)\n",
    "\n",
    "# Print 2SLS estimates\n",
    "print(f\"Estimated effect of schooling (2SLS): {beta_s_2sls:.4f}\")\n",
    "print(f\"Estimated effect of treatment (2SLS): {beta_t_2sls:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
